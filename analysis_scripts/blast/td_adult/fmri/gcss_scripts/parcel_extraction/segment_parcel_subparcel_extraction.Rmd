---
title: "segment_parcel"
author: "Jojo Hu"
date: "9/28/2022"
output: html_document
---

# All commands below must be run in an R environment inside of terminal (system() commands below evoke FSL and AFNI commands in terminal); Uncomment all the system() commands for the script to work

# Segmenting Fedorenko's parcels (Only need to be completed once)
# FSL must be installed for the following to work
```{r}
path <- "/Volumes/data/projects/blast/data/mri/imaging/scott_gcss_lpsa/data/nilearn_pipeline/fedorenko_mask/"

dir.create(paste0(path, "seg_parcels"))

mask_name <- paste0(path, "allParcels_language_SN220.nii")

# There are 12 Fedorenko parcels
for (i in seq(1:12)) {
  
  parcel_seg <- paste0(path, "seg_parcels/langloc_fedp", i, ".nii.gz")
  
  fsl_command <- as.character(paste("fslmaths", mask_name, " -uthr", i, "-thr", i, parcel_seg))
  
  # print(fsl_command)
  
  system(fsl_command)
}

# Resample individual masks (might not be necessary since Fedorenko's masks are also from the langloc task)
resampled_dir <- "/Volumes/data/projects/blast/data/mri/imaging/scott_gcss_lpsa/data/nilearn_pipeline/fedorenko_mask/resampled_seg_parcels/"

resampled_ref <- "/Volumes/data/projects/blast/data/derivatives/fitlins/analyzed/fitlins_alice/sub-blasta044/level-run_name-runlevel_sub-blasta044_run-1_contrast-intactGtDegraded_stat-z_statmap.nii.gz"
  
# "/Volumes/data/projects/blast/data/derivatives_new/first_level_output/edit_fmriprep/langloc/subjectLevel/sub-blasta044/sub-blasta044_task-langloc_contrast-intactminusdegraded_stat-z_statmap.nii.gz" 

#"/Volumes/data/projects/blast/data/derivatives_new/first_level_output/unedit_fmriprep/asl/runLevel/sub-blasta044/sub-blasta044_task-asl_run-01_contrast-syllablesminusrest_stat-z_statmap.nii.gz"


unsampledFed <- 
  list.files("/Volumes/data/projects/blast/data/mri/imaging/scott_gcss_lpsa/data/nilearn_pipeline/fedorenko_mask/seg_parcels", full.names = T)

for (i in 1:length(unsampledFed)) {
  
  unsampledParcel <- unsampledFed[i]
  
  resampled_output <- paste0(resampled_dir, "resampled_", basename(unsampledParcel))
  
  resample_command <- as.character(paste("3dresample", "-input", unsampledParcel, "-master", resampled_ref, "-prefix", resampled_output))

  print(resample_command)
  system(resample_command)
}
```



# **In MATLAB: Run scripts in MATLAB to extract minimum activation level in the top 10% activated voxels within Fedorenko parcels**



# Extract individualized sub-voxels based on the **Fedorenko** mask for all participants using **subject-level** langloc first-level data
# AFNI and FSL must be installed for the following to work
```{r}
library(stringr)
library(dplyr)
library(reshape2)

output_dir <- "/Volumes/data/projects/blast/data/mri/imaging/scott_gcss_lpsa/data/nilearn_pipeline/fedorenko_mask/indiv_langloc_parcels/unresampled_mask/"

# Read in minimal of top 10% activation value
allMini <- 
  read.csv("/Volumes/data/projects/blast/data/mri/imaging/scott_gcss_lpsa/data/nilearn_pipeline/fedorenko_mask/indiv_langloc_parcels/langloc_minimum_top_10_data.csv", stringsAsFactors = F)
# Read in subject ID for the dataset
subjectID <- read.csv("/Volumes/data/projects/blast/data/mri/imaging/scott_gcss_lpsa/data/nilearn_pipeline/renamed_id_combined.csv", stringsAsFactors = F)

library(reshape2)


allMini <- melt(allMini, id.vars = c("Row"))

colnames(allMini)[which(names(allMini) == "Row")] <- "bare_id"
colnames(allMini)[which(names(allMini) == "variable")] <- "parcel"

allMini <- merge(allMini, subjectID[,c("bare_id", "part_id")], by = c("bare_id"), all.x = T)

allMini$bare_id <- str_pad(allMini$bare_id, 3, side = "left", pad = "0")

allMini$bare_id <- as.character(allMini$bare_id)
allMini$parcel <- as.character(allMini$parcel)
```

```{r}
# List langloc individual intact > degraded z-maps 
aliceFileUE <-
  list.files("/Volumes/data/projects/blast/data/derivatives_new/first_level_output/unedit_fmriprep/langloc/subjectLevel", 
           pattern = "sub-blast*", 
           full.names = T, recursive = F)
aliceFileUE <-
  list.files(aliceFileUE,
           pattern =  "sub-blast\\S+_task-langloc_contrast-intactminusdegraded_stat-z_statmap.nii.gz", 
           full.names = T, recursive = F)

aliceFileUE <- as.data.frame(aliceFileUE)
aliceFileUE$aliceFileUE <- as.character(aliceFileUE$aliceFileUE)

aliceFile <-
  list.files("/Volumes/data/projects/blast/data/derivatives_new/first_level_output/edit_fmriprep/langloc/subjectLevel", 
           pattern = "sub-blast*", 
           full.names = T, recursive = F)
aliceFile <-
  list.files(aliceFile,
           pattern =  "sub-blast\\S+_task-langloc_contrast-intactminusdegraded_stat-z_statmap.nii.gz", 
           full.names = T, recursive = F)

aliceFile <- as.data.frame(aliceFile)
aliceFile$aliceFile <- as.character(aliceFile$aliceFile)

# Save edited fMRI outputs and remove unedited fMRI outputs that are already in edited fMRI outputs
aliceFileUE <- 
  aliceFileUE %>%
  filter(!basename(aliceFileUE) %in% basename(aliceFile$aliceFile)) 

aliceFileUE <- 
  aliceFileUE %>%
  mutate(source = str_extract(aliceFileUE, "unedit_fmriprep"))

aliceFile <- 
  aliceFile %>%
  mutate(source = str_extract(aliceFile, "edit_fmriprep"))

aliceFile <- 
  dplyr::bind_rows(aliceFileUE, aliceFile) %>%
  mutate(aliceFile = coalesce(aliceFile, aliceFileUE)) %>%
  dplyr::select(-one_of("aliceFileUE")) %>%
  mutate(basename = basename(aliceFile)) %>%
  mutate(part_id = str_extract(basename, "sub-blast(a|c)[[:digit:]]+"),
         bare_id = str_extract(basename, "(?<=sub-blast(a|c))[[:digit:]]+")) %>%
  dplyr::select(part_id, bare_id, basename, source, aliceFile) %>%
  distinct(.) %>%
  arrange(part_id)
```

```{r}
# List all parcels in langloc group-constrained mask
langloc_parcels <- 
  list.files("/Volumes/data/projects/blast/data/mri/imaging/scott_gcss_lpsa/data/nilearn_pipeline/fedorenko_mask/resampled_seg_parcels",
            pattern = "\\S+.nii.gz", full.names = T)

# Repeat each individual's row so that each individual will have the number of rows that matches the total number of parcels in the group-constrained mask
file_rep <- rep(aliceFile$aliceFile, length(unique(langloc_parcels)))

file_rep <- as.data.frame(file_rep)

file_rep$part_id <- str_extract(file_rep$file_rep, "sub-blast(a|c)[[:digit:]]+")

file_rep <-
  file_rep %>%
  arrange(file_rep)
 
# Repeat each parcel row so that each parcel will have the number of rows that matches the total number of individuals (N)
parcel_rep <- rep(langloc_parcels, times = c(nrow(file_rep)/length(langloc_parcels)))

length(parcel_rep) == nrow(file_rep)

file_rep <- cbind(file_rep, parcel_rep)

file_rep <- merge(file_rep, aliceFile, all.x = T)

file_rep$parcel <- str_extract(file_rep$parcel_rep, "(?<=resampled_seg_parcels/)\\S+(?=.nii.gz)")

# Check that merging did not create additional unwanted rows
length(parcel_rep) == nrow(file_rep)
# Check that each individual only has the set number of parcels, should return zero
file_rep %>%
  arrange(file_rep) %>%
  group_by(part_id) %>%
  dplyr::summarise(n = n()) %>%
  filter(n != length(unique(langloc_parcels)))

# Merge minimal of top 10% activation value
file_rep <- 
  merge(file_rep, allMini, by = c("part_id", "bare_id", "parcel"), all.x = T) %>%
  # Get rid of those that do not have minimal activation value in top 10% activated parcels, who are also those not in the relevant participant group
  filter(!is.na(value))

file_rep %>%
  dplyr::select(part_id) %>%
  distinct(.) %>%
  dplyr::summarise(n() == nrow(subjectID))
```


```{r}
colnames(file_rep)[which(names(file_rep) == "parcel_rep")] <- "parcel_path"

file_rep <-
  file_rep %>%
  mutate(parcel = str_remove(parcel, "resampled_"),
         group = ifelse(str_detect(part_id, "blasta"), "adult", ifelse(str_detect(part_id, "blastc"), "child", NA))) %>%
  # Set file name for individuals' output sub-parcels
  mutate(output_file = paste0(output_dir, group, "/", part_id, "_", parcel, ".nii.gz"))
```

# Generate individual masks based on lang loc parcels using **subject-level** langloc first-level data
```{r}
for (i in 1:nrow(file_rep)) {

  fsl_command <- as.character(paste("fslmaths", file_rep[i, c("aliceFile")], "-thr", file_rep[i, c("value")], "-mas", file_rep[i, c("parcel_path")], file_rep[i, c("output_file")]))
  
  print(fsl_command)
  
  # system(fsl_command)
}
```


# Resample individual masks using **subject-level** langloc first-level data
```{r}
resampled_dir <- "/Volumes/data/projects/blast/data/mri/imaging/scott_gcss_lpsa/data/nilearn_pipeline/fedorenko_mask/indiv_langloc_parcels/resampled_mask/"

# Create subject sub-folders for resampled masks
subdir <- paste0(resampled_dir, file_rep$group, "/", file_rep$bare_id)
subdir <- unique(subdir)

for (i in 1:length(subdir)) {
  dir.create(subdir[i])
}

# List resampled individual masks output
file_rep$resampled_output <- paste0(resampled_dir, file_rep$group, "/", file_rep$bare_id, "/resampled_", basename(file_rep$output_file))

resampled_ref <- "/Volumes/data/projects/blast/data/derivatives_new/first_level_output/edit_fmriprep/asl/subjectLevel/sub-blasta044/sub-blasta044_task-asl_contrast-syllablesminusrest_stat-z_statmap.nii.gz"

for (i in 1:nrow(file_rep)) {

  resample_command <- as.character(paste("3dresample", "-input", file_rep[i, c("output_file")], "-master", resampled_ref, "-prefix", file_rep[i, c("resampled_output")]))

  print(resample_command)
  
  # system(resample_command)
}
```

# Binarize all the resampled mask using **subject-level** langloc first-level data
```{r}
bin_dir <- "/Volumes/data/projects/blast/data/mri/imaging/scott_gcss_lpsa/data/nilearn_pipeline/fedorenko_mask/indiv_langloc_parcels/bin_resampled_mask/"

# Create subject sub-folders for resampled masks
subdir <- paste0(bin_dir, file_rep$group, "/", file_rep$bare_id)
subdir <- unique(subdir)

for (i in 1:length(subdir)) {
  dir.create(subdir[i])
}
# To DO: Fix Scott script to take actual ID input and thus get rid of str_extract here!
file_rep$bin_output <- paste0(bin_dir, file_rep$group, "/", file_rep$bare_id, "/bin_resampled_", str_extract(file_rep$output_file, "langloc_fedp[[:digit:]]+.nii.gz")) 

# Binarize all the resampled mask
for (i in 1:nrow(file_rep)) {

  bin_command <- as.character(paste("fslmaths", file_rep[i, c("resampled_output")], "-bin",  file_rep[i, c("bin_output")]))
  
  print(bin_command)
  
  # system(bin_command)
}
```












# Extract individualized sub-voxels based on the **Group-constrained mask** for adult
# AFNI and FSL must be installed for the following to work

# Segmenting Group-constrained mask's parcels (Only need to be completed once)
# FSL must be installed for the following to work
# Segmenting Group-constrained Parcels
# FSL must be installed for the following to work
```{r}
path <- "/Volumes/data/projects/blast/data/mri/imaging/scott_gcss_lpsa/data/nilearn_pipeline/group_constrained_mask/combined/td_adult/00001_6vox/"

dir.create("/Volumes/data/projects/blast/data/mri/imaging/scott_gcss_lpsa/data/nilearn_pipeline/group_constrained_mask/seg_parcels")

parcel <-
  read.csv(paste0(path, "LangLoc_nilearn_subject_level_00001_6voxSpacing_parcel_report.csv"), stringsAsFactors = F)

mask_name <- paste0(path, "LangLoc_nilearn_subject_level_00001_6voxSpacing_probability_map_thresh2subjs_smoothed_parcels_sig.nii.gz")

sig_parcel <- parcel[which(parcel$is_significant == 1), "parcel_numbers"]

length(sig_parcel)

for (i in sig_parcel) {
  parcel_seg <- paste0("/Volumes/data/projects/blast/data/mri/imaging/scott_gcss_lpsa/data/nilearn_pipeline/group_constrained_mask/seg_parcels/", "langloc_gcp", i, ".nii.gz")
  
  fsl_command <- as.character(paste("fslmaths", mask_name, " -uthr", i, "-thr", i, parcel_seg))
  
  print(fsl_command)
  
  system(fsl_command)
}
```

# Resample individual masks
```{r}
resampled_dir <- "/Volumes/data/projects/blast/data/mri/imaging/scott_gcss_lpsa/data/nilearn_pipeline/group_constrained_mask/resampled_seg_parcels/"

dir.create("/Volumes/data/projects/blast/data/mri/imaging/scott_gcss_lpsa/data/nilearn_pipeline/group_constrained_mask/resampled_seg_parcels")

resampled_ref <- "/Volumes/data/projects/blast/data/derivatives_new/first_level_output/edit_fmriprep/langloc/subjectLevel/sub-blasta044/sub-blasta044_task-langloc_contrast-intactminusdegraded_stat-z_statmap.nii.gz"

unsampledFed <- 
  list.files("/Volumes/data/projects/blast/data/mri/imaging/scott_gcss_lpsa/data/nilearn_pipeline/group_constrained_mask/seg_parcels", full.names = T)

for (i in 1:length(unsampledFed)) {
  
  unsampledParcel <- unsampledFed[i]
  
  resampled_output <- paste0(resampled_dir, "resampled_", basename(unsampledParcel))
  
  resample_command <- as.character(paste("3dresample", "-input", unsampledParcel, "-master", resampled_ref, "-prefix", resampled_output))

  print(resample_command)
  system(resample_command)
}
```

# **In MATLAB: Run scripts in MATLAB to extract minimum activation level in the top 10% activated voxels within group-constrained for adults and for children**


# Extract individualized sub-voxels based on the **Group-constrained** mask for all participants using **subject-level** langloc first-level data
# AFNI and FSL must be installed for the following to work
```{r}
library(stringr)
library(dplyr)
library(reshape2)

output_dir <- "/Volumes/data/projects/blast/data/mri/imaging/scott_gcss_lpsa/data/nilearn_pipeline/group_constrained_mask/indiv_langloc_parcels/unresampled_mask/"

dir.create(output_dir)
dir.create(file.path(output_dir, "adult"))
dir.create(file.path(output_dir, "child"))

# Read in minimal of top 10% activation value
adultMini <- 
  read.csv("/Volumes/data/projects/blast/data/mri/imaging/scott_gcss_lpsa/data/nilearn_pipeline/group_constrained_mask/indiv_langloc_parcels/adult_langloc_minimum_top_10_data.csv", stringsAsFactors = F)

childMini <- 
  read.csv("/Volumes/data/projects/blast/data/mri/imaging/scott_gcss_lpsa/data/nilearn_pipeline/group_constrained_mask/indiv_langloc_parcels/child_langloc_minimum_top_10_data.csv", stringsAsFactors = F)

allMini <- dplyr::bind_rows(adultMini, childMini)

# Read in subject ID for the dataset
adultID <- read.csv("/Volumes/data/projects/blast/data/mri/imaging/scott_gcss_lpsa/data/nilearn_pipeline/renamed_id_adult.csv", stringsAsFactors = F)
childID <- read.csv("/Volumes/data/projects/blast/data/mri/imaging/scott_gcss_lpsa/data/nilearn_pipeline/renamed_id_child.csv", stringsAsFactors = F)

subjectID <- dplyr::bind_rows(adultID, childID)

library(reshape2)

allMini <- reshape2::melt(allMini, id.vars = c("Row"))

colnames(allMini)[which(names(allMini) == "Row")] <- "bare_id"
colnames(allMini)[which(names(allMini) == "variable")] <- "parcel"

allMini <- merge(allMini, subjectID[,c("bare_id", "part_id")], by = c("bare_id"), all.x = T)

allMini$bare_id <- str_pad(allMini$bare_id, 3, side = "left", pad = "0")

allMini$bare_id <- as.character(allMini$bare_id)
allMini$parcel <- as.character(allMini$parcel)
```

```{r}
# List langloc individual intact > degraded z-maps 
aliceFileUE <-
  list.files("/Volumes/data/projects/blast/data/derivatives_new/first_level_output/unedit_fmriprep/langloc/subjectLevel", 
           pattern = "sub-blast*", 
           full.names = T, recursive = F)
aliceFileUE <-
  list.files(aliceFileUE,
           pattern =  "sub-blast\\S+_task-langloc_contrast-intactminusdegraded_stat-z_statmap.nii.gz", 
           full.names = T, recursive = F)

aliceFileUE <- as.data.frame(aliceFileUE)
aliceFileUE$aliceFileUE <- as.character(aliceFileUE$aliceFileUE)

aliceFile <-
  list.files("/Volumes/data/projects/blast/data/derivatives_new/first_level_output/edit_fmriprep/langloc/subjectLevel", 
           pattern = "sub-blast*", 
           full.names = T, recursive = F)
aliceFile <-
  list.files(aliceFile,
           pattern =  "sub-blast\\S+_task-langloc_contrast-intactminusdegraded_stat-z_statmap.nii.gz", 
           full.names = T, recursive = F)

aliceFile <- as.data.frame(aliceFile)
aliceFile$aliceFile <- as.character(aliceFile$aliceFile)

# Save edited fMRI outputs and remove unedited fMRI outputs that are already in edited fMRI outputs
aliceFileUE <- 
  aliceFileUE %>%
  filter(!basename(aliceFileUE) %in% basename(aliceFile$aliceFile)) 

aliceFileUE <- 
  aliceFileUE %>%
  mutate(source = str_extract(aliceFileUE, "unedit_fmriprep"))

aliceFile <- 
  aliceFile %>%
  mutate(source = str_extract(aliceFile, "edit_fmriprep"))

aliceFile <- 
  dplyr::bind_rows(aliceFileUE, aliceFile) %>%
  mutate(aliceFile = coalesce(aliceFile, aliceFileUE)) %>%
  dplyr::select(-one_of("aliceFileUE")) %>%
  mutate(basename = basename(aliceFile)) %>%
  mutate(part_id = str_extract(basename, "sub-blast(a|c)[[:digit:]]+"),
         bare_id = str_extract(basename, "(?<=sub-blast(a|c))[[:digit:]]+")) %>%
  dplyr::select(part_id, bare_id, basename, source, aliceFile) %>%
  distinct(.) %>%
  arrange(part_id)
```

```{r}
# List all parcels in langloc group-constrained mask
langloc_parcels <- 
  list.files("/Volumes/data/projects/blast/data/mri/imaging/scott_gcss_lpsa/data/nilearn_pipeline/group_constrained_mask/resampled_seg_parcels",
            pattern = "\\S+.nii.gz", full.names = T)

# Repeat each individual's row so that each individual will have the number of rows that matches the total number of parcels in the group-constrained mask
file_rep <- rep(aliceFile$aliceFile, length(unique(langloc_parcels)))

file_rep <- as.data.frame(file_rep)

file_rep$part_id <- str_extract(file_rep$file_rep, "sub-blast(a|c)[[:digit:]]+")

file_rep <-
  file_rep %>%
  arrange(file_rep)
 
# Repeat each parcel row so that each parcel will have the number of rows that matches the total number of individuals (N)
parcel_rep <- rep(langloc_parcels, times = c(nrow(file_rep)/length(langloc_parcels)))

length(parcel_rep) == nrow(file_rep)

file_rep <- cbind(file_rep, parcel_rep)

file_rep <- merge(file_rep, aliceFile, all.x = T)

file_rep$parcel <- str_extract(file_rep$parcel_rep, "(?<=resampled_seg_parcels/)\\S+(?=.nii.gz)")

# Check that merging did not create additional unwanted rows
length(parcel_rep) == nrow(file_rep)
# Check that each individual only has the set number of parcels, should return zero
file_rep %>%
  arrange(file_rep) %>%
  group_by(part_id) %>%
  dplyr::summarise(n = n()) %>%
  filter(n != length(unique(langloc_parcels)))

# Merge minimal of top 10% activation value
file_rep <- 
  merge(file_rep, allMini, by = c("part_id", "bare_id", "parcel"), all.x = T) %>%
  # Get rid of those that do not have minimal activation value in top 10% activated parcels, who are also those not in the relevant participant group
  filter(!is.na(value))

file_rep %>%
  dplyr::select(part_id) %>%
  distinct(.) %>%
  dplyr::summarise(n() == nrow(subjectID))
```


```{r}
colnames(file_rep)[which(names(file_rep) == "parcel_rep")] <- "parcel_path"

file_rep <-
  file_rep %>%
  mutate(parcel = str_remove(parcel, "resampled_"),
         group = ifelse(str_detect(part_id, "blasta"), "adult", ifelse(str_detect(part_id, "blastc"), "child", NA))) %>%
  # Set file name for individuals' output sub-parcels
  mutate(output_file = paste0(output_dir, group, "/", part_id, "_", parcel, ".nii.gz"))
```

# Generate individual masks based on lang loc parcels using **subject-level** langloc first-level data
```{r}
for (i in 1:nrow(file_rep)) {

  fsl_command <- as.character(paste("fslmaths", file_rep[i, c("aliceFile")], "-thr", file_rep[i, c("value")], "-mas", file_rep[i, c("parcel_path")], file_rep[i, c("output_file")]))
  
  print(fsl_command)
  
  system(fsl_command)
}
```


# Resample individual masks using **subject-level** langloc first-level data
```{r}
resampled_dir <- "/Volumes/data/projects/blast/data/mri/imaging/scott_gcss_lpsa/data/nilearn_pipeline/group_constrained_mask/indiv_langloc_parcels/resampled_mask/"

dir.create(resampled_dir)
dir.create(file.path(resampled_dir, "adult"))
dir.create(file.path(resampled_dir, "child"))

# Create subject sub-folders for resampled masks
subdir <- paste0(resampled_dir, file_rep$group, "/", file_rep$bare_id)
subdir <- unique(subdir)

for (i in 1:length(subdir)) {
  dir.create(subdir[i])
}

# List resampled individual masks output
file_rep$resampled_output <- paste0(resampled_dir, file_rep$group, "/", file_rep$bare_id, "/resampled_", basename(file_rep$output_file))

resampled_ref <- "/Volumes/data/projects/blast/data/derivatives_new/first_level_output/edit_fmriprep/asl/subjectLevel/sub-blasta044/sub-blasta044_task-asl_contrast-syllablesminusrest_stat-z_statmap.nii.gz"

for (i in 1:nrow(file_rep)) {

  resample_command <- as.character(paste("3dresample", "-input", file_rep[i, c("output_file")], "-master", resampled_ref, "-prefix", file_rep[i, c("resampled_output")]))

  print(resample_command)
  
  system(resample_command)
}
```

# Binarize all the resampled mask using **subject-level** langloc first-level data
```{r}
bin_dir <- "/Volumes/data/projects/blast/data/mri/imaging/scott_gcss_lpsa/data/nilearn_pipeline/group_constrained_mask/indiv_langloc_parcels/bin_resampled_mask/"

dir.create(bin_dir)
dir.create(file.path(bin_dir, "adult"))
dir.create(file.path(bin_dir, "child"))

# Create subject sub-folders for resampled masks
subdir <- paste0(bin_dir, file_rep$group, "/", file_rep$bare_id)
subdir <- unique(subdir)

for (i in 1:length(subdir)) {
  dir.create(subdir[i])
}
# To DO: Fix Scott script to take actual ID input and thus get rid of str_extract here!
file_rep$bin_output <- paste0(bin_dir, file_rep$group, "/", file_rep$bare_id, "/bin_resampled_", str_extract(file_rep$output_file, "langloc_gcp[[:digit:]]+.nii.gz")) 

# Binarize all the resampled mask
for (i in 1:nrow(file_rep)) {

  bin_command <- as.character(paste("fslmaths", file_rep[i, c("resampled_output")], "-bin",  file_rep[i, c("bin_output")]))
  
  print(bin_command)
  
  system(bin_command)
}
```






# Non-individual Parcel Analysis (Analysis just based on the group-constrained mask without individual langloc fROIs)
```{r}
# Resample group-constrained langloc parcels using ASL data first
resampled_dir <- "/Volumes/data/projects/blast/data/mri/imaging/scott_gcss_lpsa/data/nilearn_pipeline/group_constrained_mask/nonindiv_analysis/resampled_seg_parcels_asl/"

dir.create(resampled_dir)

resampled_ref <- "/Volumes/data/projects/blast/data/derivatives_new/first_level_output/edit_fmriprep/asl/subjectLevel/sub-blasta044/sub-blasta044_task-asl_contrast-syllablesminusrest_stat-z_statmap.nii.gz"

unsampledFed <- 
  list.files("/Volumes/data/projects/blast/data/mri/imaging/scott_gcss_lpsa/data/nilearn_pipeline/group_constrained_mask/seg_parcels", full.names = T)

for (i in 1:length(unsampledFed)) {
  
  unsampledParcel <- unsampledFed[i]
  
  resampled_output <- paste0(resampled_dir, "resampled_", basename(unsampledParcel))
  
  resample_command <- as.character(paste("3dresample", "-input", unsampledParcel, "-master", resampled_ref, "-prefix", resampled_output))

  print(resample_command)
  system(resample_command)
}
```

```{r}
# Resample group-constrained langloc parcels using ASL data first
bin_dir <- "/Volumes/data/projects/blast/data/mri/imaging/scott_gcss_lpsa/data/nilearn_pipeline/group_constrained_mask/nonindiv_analysis/bin_resampled_seg_parcels_asl/"

dir.create(bin_dir)

# To DO: Fix Scott script to take actual ID input and thus get rid of str_extract here!
unbinGC <- 
  list.files("/Volumes/data/projects/blast/data/mri/imaging/scott_gcss_lpsa/data/nilearn_pipeline/group_constrained_mask/nonindiv_analysis/resampled_seg_parcels_asl", full.names = T)

for (i in 1:length(unsampledFed)) {
  
  unbinParcel <- unbinGC[i]
  
  bin_output <- paste0(bin_dir, "bin_", basename(unbinParcel))
  
  bin_command <- as.character(paste("fslmaths", unbinParcel, "-bin",  bin_output))


  print(bin_command)
  system(bin_command)
}
```





**# TO DO: Need to be updated to Nilearn pipeline:**

# Extract individualized sub-voxels based on a parcel mask for children for Attentional Network based on Random vs. Rest ASL contrasts
# AFNI and FSL must be installed for the following to work
```{r}
library(stringr)
library(dplyr)
library(reshape2)

output_dir <- "/Volumes/data/projects/blast/data/mri/imaging/scott_gcss_lpsa/data/asl_attention/indiv_att_ouput/resampled_mask/child/"

# Read in minimal of top 10% activation value
childMin <- 
  read.csv("/Volumes/data/projects/blast/data/mri/imaging/scott_gcss_lpsa/data/asl_attention/child_dan_minimum_top_10_data_03_17.csv", 
           stringsAsFactors = F)
# List ASL individual random > rest z-maps 
aslRandFile <-
  list.files("/Volumes/data/projects/blast/data/derivatives/fitlins/analyzed/fitlins", 
           pattern = "sub-blastc", 
           full.names = T, recursive = F)

aslRandFile <-
  list.files(aslRandFile, 
           pattern = "level-run_name-run_sub-blastc\\d+_run-\\d+_contrast-rand[[:alpha:]]+VRest_stat-z_statmap.nii.gz", 
           full.names = T, recursive = F)

aslRandFile <- as.data.frame(aslRandFile)

aslRandFile$aslRandFile <- as.character(aslRandFile$aslRandFile)

aslRandFile$basename <- basename(as.character(aslRandFile$aslRandFile))

aslRandFile$part_id <- str_extract(aslRandFile$basename, "sub-blastc[[:digit:]]+")

aslRandFile$bare_id <- str_extract(aslRandFile$basename, "(?<=sub-blastc)[[:digit:]]+")

aslRandFile$run <- str_extract(aslRandFile$basename, "(?<=run-)[[:digit:]]")

aslRandFile$bare_run <- paste0(aslRandFile$bare_id, "_", aslRandFile$run, "_", tolower(str_extract(aslRandFile$basename, "(Speech|Tone)")))

aslRandFile$stimuli <- str_extract(aslRandFile$basename, "(Speech|Tone)")

aslRandFile$condition <- str_extract(aslRandFile$basename, "(str|rand)")

aslRandFile12 <- 
  aslRandFile %>%
  filter(run == "1" | run == "2") %>%
  filter((stimuli == "Speech" & condition == "str") | (stimuli == "Tone" & condition == "rand"))

aslRandFile34 <- 
  aslRandFile %>%
  filter(run == "3" | run == "4") %>%
  filter((stimuli == "Speech" & condition == "rand") | (stimuli == "Tone" & condition == "str"))

aslRandFile <- rbind(aslRandFile12, aslRandFile34)

aslRandFile <- 
  aslRandFile %>%
  arrange(aslRandFile)

# List all parcels in langloc group-constrained mask
dan_parcels <- 
  list.files("/Volumes/data/projects/blast/data/mri/imaging/scott_gcss_lpsa/data/dorsal_attention_parcel/conn_resampled_parcel",
            pattern = "resampled_conn_dan.nii.gz", full.names = T)

# aslRandFile$parcel <- str_extract(aslRandFile$parcel, "resampled_conn_dan")

# Add parcel to aslRandFile
file_rep <- aslRandFile
file_rep$parcel_path <- dan_parcels
# Check that each individual only has the set number of parcels
file_rep %>%
  arrange(file_rep) %>%
  group_by(part_id, run) %>%
  dplyr::summarise(n = n()) %>%
  filter(n != length(unique(dan_parcels)))

library(reshape2)
childMin <- melt(childMin, id.vars = c("Row"))

colnames(childMin)[which(names(childMin) == "Row")] <- "bare_run"
colnames(childMin)[which(names(childMin) == "variable")] <- "parcel"

# Merge minimal of top 10% activation value
file_rep <- merge(file_rep, childMin, all.x = T)

# Check that each individual only has the set number of parcels
file_rep %>%
  arrange(file_rep) %>%
  group_by(part_id, run) %>%
  dplyr::summarise(n = n()) %>%
  filter(n != length(unique(dan_parcels)))

# Set file name for individuals' output sub-parcels
file_rep$output_file <- paste0(output_dir, file_rep$part_id, "_", "run-", file_rep$run, "_", file_rep$parcel, ".nii.gz") 

# Generate individual masks based on lang loc parcels
for (i in 1:nrow(file_rep)) {

  fsl_command <- as.character(paste("fslmaths", file_rep[i, c("aslRandFile")], "-thr", file_rep[i, c("value")], "-mas", file_rep[i, c("parcel_path")], file_rep[i, c("output_file")]))

  system(fsl_command)
}


# Binarize all the resampled mask
bin_dir <- "/Volumes/data/projects/blast/data/mri/imaging/scott_gcss_lpsa/data/asl_attention/indiv_att_ouput/bin_resampled_mask/child/"

# Create subject sub-folders for resampled masks
subdir <- paste0(bin_dir, file_rep$bare_id)
subdir <- unique(subdir)

for (i in 1:length(subdir)) {
  dir.create(subdir[i])
}
# To DO: Fix Scott script to take actual ID input and thus get rid of str_extract here!
file_rep$bin_output <- paste0(bin_dir, file_rep$bare_id, "/bin_resampled_", str_extract(file_rep$output_file, "run-[[:digit:]]_"), tolower(file_rep$stimuli), "_", tolower(file_rep$condition), "_dan.nii.gz")

# Binarize all the resampled mask
for (i in 1:nrow(file_rep)) {

  bin_command <- as.character(paste("fslmaths", file_rep[i, c("output_file")], "-bin",  file_rep[i, c("bin_output")]))

  system(bin_command)
}
```


# Extract individualized sub-voxels based on a parcel mask for adults for Attentional Network based on Random vs. Rest ASL contrasts
# AFNI and FSL must be installed for the following to work
```{r}
library(stringr)
library(dplyr)
library(reshape2)

output_dir <- "/Volumes/data/projects/blast/data/mri/imaging/scott_gcss_lpsa/data/asl_attention/indiv_att_ouput/resampled_mask/adult/"

# Read in minimal of top 10% activation value
childMin <- 
  read.csv("/Volumes/data/projects/blast/data/mri/imaging/scott_gcss_lpsa/data/asl_attention/adult_dan_minimum_top_10_data_03_17.csv", 
           stringsAsFactors = F)
# List ASL individual random > rest z-maps 
aslRandFile <-
  list.files("/Volumes/data/projects/blast/data/derivatives/fitlins/analyzed/fitlins", 
           pattern = "sub-blasta", 
           full.names = T, recursive = F)

aslRandFile <-
  list.files(aslRandFile, 
           pattern = "level-run_name-run_sub-blasta\\d+_run-\\d+_contrast-rand[[:alpha:]]+VRest_stat-z_statmap.nii.gz", 
           full.names = T, recursive = F)

aslRandFile <- as.data.frame(aslRandFile)

aslRandFile$aslRandFile <- as.character(aslRandFile$aslRandFile)

aslRandFile$basename <- basename(as.character(aslRandFile$aslRandFile))

aslRandFile$part_id <- str_extract(aslRandFile$basename, "sub-blasta[[:digit:]]+")

aslRandFile$bare_id <- str_extract(aslRandFile$basename, "(?<=sub-blasta)[[:digit:]]+")

aslRandFile$run <- str_extract(aslRandFile$basename, "(?<=run-)[[:digit:]]")

aslRandFile$bare_run <- paste0(aslRandFile$bare_id, "_", aslRandFile$run, "_", tolower(str_extract(aslRandFile$basename, "(Speech|Tone)")))

aslRandFile$stimuli <- str_extract(aslRandFile$basename, "(Speech|Tone)")

aslRandFile$condition <- str_extract(aslRandFile$basename, "(str|rand)")

aslRandFile12 <- 
  aslRandFile %>%
  filter(run == "1" | run == "2") %>%
  filter((stimuli == "Speech" & condition == "str") | (stimuli == "Tone" & condition == "rand"))

aslRandFile34 <- 
  aslRandFile %>%
  filter(run == "3" | run == "4") %>%
  filter((stimuli == "Speech" & condition == "rand") | (stimuli == "Tone" & condition == "str"))

aslRandFile <- rbind(aslRandFile12, aslRandFile34)

aslRandFile <- 
  aslRandFile %>%
  arrange(aslRandFile)

# List all parcels in langloc group-constrained mask
dan_parcels <- 
  list.files("/Volumes/data/projects/blast/data/mri/imaging/scott_gcss_lpsa/data/dorsal_attention_parcel/conn_resampled_parcel",
            pattern = "\\S+.nii.gz", full.names = T)

# aslRandFile$parcel <- str_extract(aslRandFile$parcel, "resampled_conn_dan")

# Add parcel to aslRandFile
file_rep <- aslRandFile
file_rep$parcel_path <- dan_parcels
# Check that each individual only has the set number of parcels
file_rep %>%
  arrange(file_rep) %>%
  group_by(part_id, run) %>%
  dplyr::summarise(n = n()) %>%
  filter(n != length(unique(dan_parcels)))

library(reshape2)
childMin <- melt(childMin, id.vars = c("Row"))

colnames(childMin)[which(names(childMin) == "Row")] <- "bare_run"
colnames(childMin)[which(names(childMin) == "variable")] <- "parcel"

# Merge minimal of top 10% activation value
file_rep <- merge(file_rep, childMin, all.x = T)

# Check that each individual only has the set number of parcels
file_rep %>%
  arrange(file_rep) %>%
  group_by(part_id, run) %>%
  dplyr::summarise(n = n()) %>%
  filter(n != length(unique(dan_parcels)))

# Set file name for individuals' output sub-parcels
file_rep$output_file <- paste0(output_dir, file_rep$part_id, "_", "run-", file_rep$run, "_", file_rep$parcel, ".nii.gz") 

# Generate individual masks based on lang loc parcels
for (i in 1:nrow(file_rep)) {

  fsl_command <- as.character(paste("fslmaths", file_rep[i, c("aslRandFile")], "-thr", file_rep[i, c("value")], "-mas", file_rep[i, c("parcel_path")], file_rep[i, c("output_file")]))

  system(fsl_command)
}


# Binarize all the resampled mask
bin_dir <- "/Volumes/data/projects/blast/data/mri/imaging/scott_gcss_lpsa/data/asl_attention/indiv_att_ouput/bin_resampled_mask/adult/"

# Create subject sub-folders for resampled masks
subdir <- paste0(bin_dir, file_rep$bare_id)
subdir <- unique(subdir)

for (i in 1:length(subdir)) {
  dir.create(subdir[i])
}
# To DO: Fix Scott script to take actual ID input and thus get rid of str_extract here!
file_rep$bin_output <- paste0(bin_dir, file_rep$bare_id, "/bin_resampled_", str_extract(file_rep$output_file, "run-[[:digit:]]_"), tolower(file_rep$stimuli), "_", tolower(file_rep$condition), "_dan.nii.gz")

# Binarize all the resampled mask
for (i in 1:nrow(file_rep)) {

  bin_command <- as.character(paste("fslmaths", file_rep[i, c("output_file")], "-bin",  file_rep[i, c("bin_output")]))

  system(bin_command)
}
```




